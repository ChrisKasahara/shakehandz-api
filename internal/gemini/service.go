package gemini

import (
	"encoding/json"
	"fmt"
	"log"
	"shakehandz-api/internal/humanresource"
	cache_ai "shakehandz-api/internal/shared/cache/ai"
	gmsg "shakehandz-api/internal/shared/message/gmail"
	"shakehandz-api/prompts"
	"sort"
	"strings"
	"sync"

	"github.com/gin-gonic/gin"
	"github.com/google/generative-ai-go/genai"
	"github.com/redis/go-redis/v9"
	"golang.org/x/sync/errgroup"
	"golang.org/x/sync/semaphore"
	"google.golang.org/api/gmail/v1"
	"gorm.io/gorm"
)

// ã€€Gmailãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å–å¾—â†’Geminiè§£æâ†’ï¼ˆå°†æ¥ï¼‰DBä¿å­˜
type Service struct {
	Fetcher gmsg.MessageIF
	DB      *gorm.DB
	rdb     *redis.Client
}

func NewGeminiService(f gmsg.MessageIF, db *gorm.DB, rdb *redis.Client) *Service {
	return &Service{Fetcher: f, DB: db, rdb: rdb}
}

func (s *Service) Run(c *gin.Context, client *Client, gmail_svc *gmail.Service) (bool, error) {
	ctx := c.Request.Context()
	fmt.Println("Negoã¯Gmailã‚’å–å¾—ä¸­")

	// DBæ—¢å­˜ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDã‚’é™¤å¤–ã—ãŸæœªå‡¦ç†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æœ€å¤§Nä»¶å–å¾—
	msgs, err := s.fetchUnprocessedMessages(c, gmail_svc, 9)
	if err != nil {
		return false, err
	}

	// æœªå‡¦ç†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒãªã„å ´åˆã¯ç©ºã®çµæœã‚’è¿”ã™
	if len(msgs) == 0 {
		fmt.Println("æœ€æ–°ã®ãƒ¡ãƒ¼ãƒ«ã¯ã™ã¹ã¦å‡¦ç†æ¸ˆã¿ã§ã™")
		return false, nil
	}

	fmt.Println("Gmailå–å¾—ã‚’å®Œäº†ã€‚ä»Šå›ã®è§£æä»¶æ•°ã¯", len(msgs), "ä»¶ã§ã™ã€‚Negoã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ä¿¡ä¸­")

	// chunkArrayã§åˆ†å‰²ï¼ˆJSONæ–‡å­—åˆ—ã®é…åˆ—ã¨ã—ã¦ï¼‰
	chunkedMsgs := chunkArray(msgs, 3)

	// å…±æœ‰ãƒ¢ãƒ‡ãƒ«ã®æµ…ã„ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦SystemInstructionã‚’ä¸€åº¦ã ã‘è¨­å®š
	localModel := client.Model
	localModel.SystemInstruction = &genai.Content{
		Role:  "system",
		Parts: []genai.Part{genai.Text(prompts.HRInstruction)},
	}
	fmt.Println("Negoã¯æº–å‚™å®Œäº†ã€‚ç¶šã„ã¦å¤‰æ›å‡¦ç†ã¸ç§»è¡Œ")
	progressStatus := cache_ai.JobStatus{
		JobID:   "status",
		Status:  "pending",
		Message: "ãƒ¡ãƒ¼ãƒ«å†…å®¹ã®æ§‹é€ åŒ–ã‚’å­¦ç¿’ä¸­...",
	}
	if err := cache_ai.UpdateStatusInRedis(c.Request.Context(), s.rdb, progressStatus); err != nil {
		log.Printf("ERROR: Failed to update redis: %v", err)
	}

	g, ctx := errgroup.WithContext(ctx)
	var mu sync.Mutex
	sem := semaphore.NewWeighted(5)
	var humanResources []humanresource.HumanResource

	// SystemInstructionè¨­å®šæ¸ˆã¿ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’å„ã‚´ãƒ«ãƒ¼ãƒãƒ³ã§ä½¿ç”¨
	for _, cmsg := range chunkedMsgs {
		chunk := cmsg // rangeå¤‰æ•°ã®ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ£æ•æ‰å¯¾ç­–
		if len(chunk) == 0 {
			continue
		}

		if err := sem.Acquire(ctx, 1); err != nil {
			return false, fmt.Errorf("ã‚»ãƒãƒ•ã‚©ã®å–å¾—ã«å¤±æ•—: %w", err)
		}

		g.Go(func() error {
			defer sem.Release(1)

			// äº‹å‰è¨­å®šã•ã‚ŒãŸãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã§GenerateContentã‚’å‘¼ã³å‡ºã—
			geminiResponse, geminiResErr := localModel.GenerateContent(ctx, genai.Text(chunk))
			if geminiResErr != nil {
				log.Printf("Gemini API å‘¼ã³å‡ºã—å¤±æ•—: %v", geminiResErr)
				return fmt.Errorf("Gemini API å‘¼ã³å‡ºã—å¤±æ•—: %w", geminiResErr)
			}

			if geminiResponse == nil {
				log.Printf("Gemini ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒ nil ã§ã™")
				return fmt.Errorf("Gemini ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒ nil ã§ã™")
			}

			geminiResponsePart, ok := ExtractText(geminiResponse)
			if !ok {
				log.Printf("Gemini ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã®æ–‡å­—åˆ—å¤‰æ›ä¸æ­£: %v", geminiResponsePart)
				return fmt.Errorf("Gemini ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã®æ–‡å­—åˆ—å¤‰æ›ä¸æ­£: %s", geminiResponsePart)
			}

			trimmedResponse := TrimPrefixAndSuffixGeminiResponse(geminiResponsePart)

			ChunkHumanResources := []humanresource.HumanResource{}

			if err := json.Unmarshal([]byte(trimmedResponse), &ChunkHumanResources); err != nil {
				log.Printf("JSON Unmarshalå¤±æ•—: %v", err)
				return fmt.Errorf("JSON Unmarshalå¤±æ•—: %w", err)
			}

			for _, hr := range ChunkHumanResources {
				mu.Lock()
				humanResources = append(humanResources, hr)
				mu.Unlock()
				progressStatus = cache_ai.JobStatus{
					JobID:   "status",
					Status:  "processing",
					Message: "é †èª¿ã«å¤‰æ›ä½œæ¥­ã‚’é–‹å§‹ã—ã¦ã„ã‚‹ã‚ˆã†ã§ã™ï¼",
				}
				if err := cache_ai.UpdateStatusInRedis(c.Request.Context(), s.rdb, progressStatus); err != nil {
					log.Printf("ERROR: Failed to update redis: %v", err)
				}
			}

			return nil
		})
	}

	if err := g.Wait(); err != nil {
		log.Printf("fetcher: detail fetch error: %v", err)
		return false, err
	}

	// å¿µã®ç‚ºã€MessageIDã®é‡è¤‡ã‚’é™¤å¤–
	seen := make(map[string]struct{}, len(humanResources))
	uniq := make([]humanresource.HumanResource, 0, len(humanResources))

	for _, hr := range humanResources {
		mid := strings.TrimSpace(hr.MessageID)
		if mid == "" {
			uniq = append(uniq, hr)
			continue
		}
		if _, ok := seen[mid]; ok {
			continue
		}
		seen[mid] = struct{}{}
		uniq = append(uniq, hr)
	}

	humanResources = uniq

	fmt.Println("Negoã¯å…¨ã¦ã®å¤‰æ›ã‚’å®Œäº†ã—ã¾ã—ãŸã€‚ç·ä»¶æ•°ï¼š", len(humanResources), "ä»¶ã§ã™ã€‚æœ€å¾Œã®æ•´å½¢ã‚’è¡Œãªã£ã¦ã„ã¾ã™")

	// æ—¥ä»˜ã§é™é †
	sort.Slice(humanResources, func(i, j int) bool {
		return humanResources[i].CreatedAt.Unix() > humanResources[j].CreatedAt.Unix()
	})

	fmt.Println("Negoã¯ä½œæ¥­ã‚’ä¿å­˜ä¸­")
	// DBä¿å­˜å‡¦ç†
	if len(humanResources) > 0 {
		if err := s.DB.Create(&humanResources).Error; err != nil {
			return false, fmt.Errorf("DBä¿å­˜å¤±æ•—: %w", err)
		}
	}

	progressStatus = cache_ai.JobStatus{
		JobID:   "status",
		Status:  "completed",
		Message: "å…¨ã¦ã®ä½œæ¥­ã‚’çµ‚ãˆã¾ã—ãŸ ğŸ‰",
	}
	if err := cache_ai.UpdateStatusInRedis(c.Request.Context(), s.rdb, progressStatus); err != nil {
		log.Printf("ERROR: Failed to update redis: %v", err)
	}
	return true, nil
}
